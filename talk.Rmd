---
title: Deep Learning -- The Big Picture
author: C. Heumann, M. AÃŸenmacher, D. Schalk
date: \today
output:
  beamer_presentation:
    includes:
      in_header: "style/preamble_reisensburg.sty"
    template: "style/custom_pandoc.tex"
---



# Brief History of Deep Learning

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=1]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=2]{images/dl_history1.pdf}}
jaddtocounter{framenumber}{-1}

\# Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=3]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=4]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=5]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=1]{images/dl_history2.pdf}}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=2]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=3]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=4]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=5]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 3

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=1]{images/dl_history3.pdf}}

## Deep Learning Timeline - 3

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=2]{images/dl_history3.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 3

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=3]{images/dl_history3.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 3

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=4]{images/dl_history3.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 3

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=5]{images/dl_history3.pdf}}
\addtocounter{framenumber}{-1}

# What is Possible With Deep Learning?

## Deep Learning Applications
<!-- ## Imitating Humans - 1

\begin{itemize}
  \item Turing test:

  \begin{minipage}{\textwidth}
    \begin{minipage}{0.6\textwidth}
    \begin{itemize}
      \item Developed by Alan Turing in 1950
      \item Test of a machine's ability to exhibit intelligent behavior
      \item Player C, the interrogator, is given the task of trying to determine which player, A or B, is a computer and which is a human
    \end{itemize}
    \end{minipage}
    \hfill
    \begin{minipage}{0.25\textwidth}
    \includegraphics[width=\textwidth]{images/turing_test.png}
    \end{minipage}
  \end{minipage}
\end{itemize}
 -->
-   Supervised learning tasks

-   Object Recognition -- Seeing:
\begin{center}
\includegraphics[width=5cm,trim={1cm 0cm 1cm 0cm}]{images/image_recognition.pdf}
\end{center}

-   Speech Recognition and NLP -- Hearing and understanding text:
\begin{center}
\includegraphics[width=7cm,trim={0cm 4cm 0cm 4cm}]{images/speech_recognition.pdf}
\end{center}

## Deep Learning Applications

-   And know we try to teach them creativity:
    -   __Music and Text Generation__ \
        Example of generated text trained on Trump tweets: \
        *"The Fake News Media is a great people of the president was a great people of the many people who would be a great people of the president was a big crowd of the statement of the media is a great people of the people of the statement of the people ..."* \
        ... could be better.
    - __Neural Style Transfer__
\begin{center}
\includegraphics[width=0.7\textwidth,trim={1cm 4cm 1cm 4cm}]{images/neural_style_transfer.pdf}
\end{center}
    -   ...

## Some remarks on NLP

- The world's largest companies are investing heavily in NLP:
  Google, Facebook, Amazon, Apple, Microsoft, ...
- But still: a lot of (yet) unsolved problems and challenges
- Innovations are more and more open-sourced
- There's a variety of different applications of NLP
  in everyday life you might not be aware of
- Once you see them, it soon becomes obvious

## Neural Machine Translation

\begin{center}
\includegraphics[width=0.9\textwidth]{images/machine-translation.png}
\end{center}

- Two different NLP tasks are hiding in this picture..
- __Underlying task__: Text generation

## A brief History of Machine Translation

- __Rule-Based Machine Translation__ (50s -- 80s)
    + Dictionaries + Grammatical Rules
- __Example-Based Machine Translation__ (80s -- 90s)
    + First suggested by Makoto Nagao (1984)
    + Based on bilingual text corpora
- __Statistical Machine Translation__ (90s -- 10s)
    + Driven by IBM guys
- __Neural Machine Translation__ (last few years)
    + Based on neural networks (LSTMs, Transformers)

## Auto Completion

\begin{center}
\includegraphics[width=0.9\textwidth]{images/auto-completion.png}
\end{center}

- You might also know this from your smartphone keyboard
- __Underlying task__: Predict the next word given the previous words (+ individual browsing history)

## Spam filters

\begin{center}
\includegraphics[width=0.9\textwidth]{images/spam-detection.png}
\end{center}

- Indeed, spam filters are often surprisingly simple systems
- __Underlying task__: Document classification (Naive Bayes or Logistic Regression)

## Argument Mining

\begin{center}
\includegraphics[width=0.9\textwidth]{images/argument-mining_small.png}
\end{center}

- Detection and ranking of arguments pro/contra a certain topic
-  __Underlying task__: Document classification and/or Sequence tagging

## Chatbots

\begin{center}
\includegraphics[width=0.8\textwidth]{images/chatbots_small.png}
\end{center}

- We experience chatbots on a growing number of websites
- __Underlying task__: Natural language understanding / Text generation

## Information Retrieval

 <center>

 _Alexa, what is the capital of Australia?_

 </center>

- __Underlying task__: Question Answering / Information extraction

## (Some) Further examples

- __Sentiment analysis__ / __Text classification__
    + Determine, whether a document is positive/neutral/negative
- __Text Generation__
    + Example: [_OpenAI GPT2_](https://openai.com/blog/better-language-models/)
- __Named Entity Recognition__
    + Search for certain entities (e.g. person, location, etc.)
- __Image Captioning__
    + Hybrid task (Computer Vision + NLP)
- __Dependency Parsing__
    + Determine the grammatical structure of text
- __Part-of-speech tagging__
    + Tagging words according to their role in a text

# How Deep Learning Works

## The Perceptron

- The perceptron was invented by Frank Rosenblatt 1957.
  \begin{figure}
  \includegraphics[width=4cm]{images/mark_i_perceptron.png}
  \caption{\footnotesize The Mark I Perceptron}
  \end{figure}

- It is the basic computational unit for neural networks.

## Singlelayer Perceptron

- Weighted sum of input values transformed by an activation function $s$
- If $s$ is the sigmoid function $(1 + \exp{\sum})^{-1}$, then the perceptron does exactly the same as the logistic regression

\begin{center}
\includegraphics[width=\textwidth,trim={2cm 3cm 1cm 2cm}]{images/perceptron.pdf}
\end{center}

## Multilayer Perceptron

-   Stacking of multiple perceptrons
-   Corresponds to stacking GLM models
-   Number of parameter grows very fast \
    $\rightarrow$ Optimization becomes more difficult

\begin{center}
\includegraphics[width=\textwidth,trim={2cm 3cm 1cm 1cm}]{images/fully_connected.pdf}
\end{center}


## Optimizer

-   Having that much parameter/weights to find, standard optimizer like Gradient Descent may fail
-   Therefore, much effort was spend to get faster optimizer like adam, rmsprop, etc.:
\begin{figure}
\includegraphics[width=0.4\textwidth]{images/optimizer.jpg}
\caption{\scriptsize \textbf{Source:} Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.}
\end{figure}

## Input Source Images

-   Deep Learning is well known for handling more complex data structures like images, text, voice recordings etc.
-   When using images as input, one image becomes one observation:

\begin{center}
\includegraphics[width=0.4\textwidth]{images/mnist8.png}
\end{center}

-   But, how to analyse images? We have to make use of the spatial structure, but how?


## Input Source Text

-   Another typical data format are texts:

\begin{center}
\includegraphics[width=0.8\textwidth, trim={0cm 3cm 0cm 3cm}]{images/rnn.pdf}
\end{center}

-   But, how to analyse text sources? We also have to consider the recurrent dependencies of text, but how?

## Convolution - As Operation

-   Extraction of features of the input data:

\begin{center}
\includegraphics[width=0.6\textwidth]{images/conv_sobel.png}
\end{center}

## Convolution - As Operation

\begin{figure}
\includegraphics[width=\textwidth]{images/sobel.pdf}
\caption{\scriptsize \textbf{Note:} The recognition of edges and corners requires a multiple application of the operator.}
\end{figure}

## Convolution - In Neural Networks

-   Filters, like the Sobel filter, are obtained by thinking long and hard about what should be obtained from a filter (like edges).
-   In Deep Learning these filters are learned during the training and automatically generate new features:
\begin{figure}
\includegraphics[width=0.7\textwidth]{images/conv_feat.png}
\caption{\scriptsize \textbf{Source:} Lee, H., Grosse, R., Ranganath, R., \& Ng, A. Y. (2011). Unsupervised learning of hierarchical representations with convolutional deep belief networks. Communications of the ACM, 54(10), 95-103. \textit{\enquote{Each feature can be thought of as a filter, which filters the input image for that feature (a nose). If the feature is found, the responsible unit or units generate large activations, which can be picked up by the later classifier stages as a good indicator that the class is present.}}}
\end{figure}

## Pooling

Down-sampling of images:

\begin{itemize}\item[$\rightarrow$] Less weights to fit
  \begin{itemize}\item[$\rightarrow$] Smaller net size (less memory usage, faster fitting process)
    \begin{itemize}\item[$\rightarrow$] Reduces overfitting \end{itemize}
  \end{itemize}
\end{itemize}

\includegraphics[width=\textwidth,trim={2cm 2cm 3cm 3cm}]{images/max_pooling.pdf}

## Lets Get Deep

-   The power of Deep Neural Nets comes from chaining hidden layer such as convolution layers, pooling layers, and so on
-   This deep structure allows the network to create powerful features and explore complex structures within the data
-   VGG16 architecture:

\begin{figure}
\includegraphics[width=0.5\textwidth]{images/vgg_net.png}
\caption{\scriptsize \textbf{Source:} \url{https://www.cs.toronto.edu/~frossard/post/vgg16/}}
\end{figure}



<!--
| Model             | Size   | Top-1 Accuracy | Top-5 Accuracy | Parameters   | Depth |
| ------------------|--------|----------------|----------------|--------------| ----- |
| Xception          |  88 MB |          0.790 |          0.945 |  22,910,480  |  126  |
| VGG16             | 528 MB |          0.713 |          0.901 |  138,357,544 |   23  |
| VGG19             | 549 MB |          0.713 |          0.900 |  143,667,240 |   26  |
| ResNet50          |  99 MB |          0.749 |          0.921 |  25,636,712  |  168  |
| InceptionV3       |  92 MB |          0.779 |          0.937 |  23,851,784  |  159  |
| InceptionResNetV2 | 215 MB |          0.803 |          0.953 |  55,873,736  |  572  |
| MobileNet         |  16 MB |          0.704 |          0.895 |  4,253,864   |   88  |
| MobileNetV2       |  14 MB |          0.713 |          0.901 |  3,538,984   |   88  |
| DenseNet121       |  33 MB |          0.750 |          0.923 |  8,062,504   |  121  |
| DenseNet169       |  57 MB |          0.762 |          0.932 |  14,307,880  |  169  |
| DenseNet201       |  80 MB |          0.773 |          0.936 |  20,242,984  |  201  |
| NASNetMobile      |  23 MB |          0.744 |          0.919 |  5,326,716   |    -  |
| NASNetLarge       | 343 MB |          0.825 |          0.960 |  88,949,818  |    -  |
-->

## Pre Trained Models

\scriptsize

| __Model__         | __Size__ | __Parameters__ | __Depth__ |
| ----------------- | --------:| --------------:|:---------:|
| Xception          |  88 MB   |  22,910,480    |       126 |
| VGG16             | 528 MB   |  138,357,544   |        23 |
| VGG19             | 549 MB   |  143,667,240   |        26 |
| ResNet50          |  99 MB   |  25,636,712    |       168 |
| InceptionV3       |  92 MB   |  23,851,784    |       159 |
| InceptionResNetV2 | 215 MB   |  55,873,736    |       572 |
| MobileNet         |  16 MB   |  4,253,864     |        88 |
| MobileNetV2       |  14 MB   |  3,538,984     |        88 |
| DenseNet121       |  33 MB   |  8,062,504     |       121 |
| DenseNet169       |  57 MB   |  14,307,880    |       169 |
| DenseNet201       |  80 MB   |  20,242,984    |       201 |
| NASNetMobile      |  23 MB   |  5,326,716     |         - |
| NASNetLarge       | 343 MB   |  88,949,818    |         - |

\begin{center}
\textbf{Source:} \href{https://keras.io/applications/}{\alert{Keras Documentation}}
\end{center}

\normalsize

## A primer on Transfer Learning

- What are "_Pre Trained models_"?
    + Knowledge gained from solving one task can be potentially transfered to other tasks
    + Pre Training on a relatively general data set (of images)
    + Fine Tuning on a task specific data set at hand
    + _For images:_
        + Pre Trained model has already learned something about shapes and edges
        + Potentially also already about more complex concepts
    + _For text:_
        + Pre Trained model has already some knowledge of syntax & semantic

## A primer on Transfer Learning

\begin{figure}
\includegraphics[width=0.75\textwidth]{images/transfer_learning_taxonomy-1.png}
\caption{\scriptsize \textbf{Source:} \url{https://ruder.io/thesis/index.html}}
\end{figure}

## A primer on Transfer Learning

- Good points to start:
    + \url{https://ruder.io/state-of-transfer-learning-in-nlp/}
    + Many tutorials, etc. available online:
      \url{https://lmgtfy.com/?q=transfer+learning+nlp}

# Challenges in Deep Learning

## Challenges in Deep Learning

-   __Finding a Good Architecture__ \
    Having that many possibilities of combining hidden layer, optimizer, and activation functions we run into the problem of finding a good architecture. \
    \begin{itemize}
      \item[$\rightarrow$] Transfer learning, use already trained models, adjust them to your data situation, and train (a subset of) the weights.
      \item[$\rightarrow$] Architecture search
    \end{itemize}

-   __Expensive Training__ \
    Training of DNNs require billions of simple operations, hence training \alert{one} DNN might take weeks. \
    \begin{itemize}\item[$\rightarrow$] Use GPU server for serious applications. Why? See next slides.\end{itemize}



# Tech Stack

## Hardware

- Deep Neural Networks require special hardware to be trained efficiently.
- The training is done using __G__raphics __P__rocessing __U__nits and a special programming language called __CUDA__.
- Training on standard CPUs takes a very long long time and gets infeasible for anything but toy examples.

\begin{minipage}{0.49\textwidth}
\begin{figure}
\includegraphics[width=5cm]{images/cpu_training.pdf}
\caption{Each CPU can do $2-8$ parallel computations.}
\end{figure}
\end{minipage}
\begin{minipage}{0.49\textwidth}
\begin{figure}
\includegraphics[width=5cm]{images/gpu_training.pdf}
\caption{A single GPU can do thousands of simple parallel computations.}
\end{figure}
\end{minipage}


## Software

CUDA is a very __low level__ programming language and thus writing code for Deep Learning requires a lot of work.
Software projects, like TensorFlow and abstract CUDA provide additional functionality.


\begin{minipage}{0.4\textwidth}
The basic concept of calculations in deep neural networks is a \textit{computational graph},
which describes the dependency structure of the network.
\end{minipage}
\begin{minipage}{0.58\textwidth}
\begin{figure}
\includegraphics[width=5cm]{images/compgraph1.png}
\caption{Computational graph for $f(XW + b)$.}
\end{figure}
\end{minipage}


## TensorFlow

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/tensorflow.jpeg}
\end{figure}


- Open-source framework developed by google.

- Rather low-level and aimed to directly work with computational graphs.

- Mainly support for Python (R support only via _reticulate_).

- Widely used and well documented.


## Keras

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/keras.png}
\end{figure}

- Open-source high-level API for Deep Learning.

- Can run on top of __TensorFlow__, CNTK or Theano.

- Mainly support for Python (R support only via __reticulate__).

- Widely used and well documented.

## Keras in R

\begin{minipage}{\textwidth}
  \begin{minipage}{0.5\textwidth}
    \includegraphics{images/tech_stack.png}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \includegraphics{images/tech_stack_R.png}
  \end{minipage}
\end{minipage}

- Deep learning in R is the same as in Python.

- Communication from R to Python via __reticulate__.

## Keras in R

- Syntax is (almost) identical.

- Same functionality.

- Same speed (slight overhead for communication between R and Python).

- More difficult to debug.

Useful resources:

\url{https://keras.rstudio.com/}

\url{https://rstudio.github.io/reticulate/articles/introduction.html}


## PyTorch

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/pytorch.png}
\end{figure}


- Open-source framework developed by facebook.

- Reimplementation of Torch.

- Only support for Python.

- Widely used and well documented.

## PyTorch

- PyToch uses dynamic computational graphs. Instead of define and run the graph, the graph is defined by run:

\begin{figure}
  \centering
    \includegraphics[width=0.6\textwidth]{images/pytorch_graph.png}
    \caption{Source: \url{https://github.com/pytorch/pytorch}}
\end{figure}


<!---
## Fast.ai

\begin{figure}
  \centering
    \includegraphics[width=4cm]{images/fastai.png}
\end{figure}


- Open-source high-level API build on top of PyTorch.

- Still in alpha version.

- Only support for Python.

- Initially developed for the _Practical Deep Learning for Coders_ online course.

## mxnet

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/mxnet.png}
\end{figure}

- Open-source framework in the Apache foundation.

- Scalable, allow easy training on multiple GPUs in parallel.

- Supports multiple languages (C++, Python, R, Julia, Matlab, JavaScript, Go, Scala, Pearl).

- Not as widely used as other frameworks.
-->


# Where to Start in the DL Jungle?

## Getting Started with Keras - Installation

-   Install keras using `pip` (or pip3 for python3) from the command line:

\scriptsize
```python
# python
pip install --upgrade tensorflow
pip install keras

# python3
pip3 install --upgrade tensorflow
pip3 install keras
```
\normalsize

-   On linux you may need to run the commands as `sudo`.
-   The GPU version requires `CUDA` and `cuDNN`. Installation is then done by

\scriptsize
```python
pip install --upgrade tensorflow-gpu
```
\normalsize

## Getting Started with Keras - Overview

-   Instead of introducing theory, we want to get into the topic by applying it.

-   We using examples similar to the book \href{https://www.manning.com/books/deep-learning-with-python}{\alert{Deep Learning with Python}} that are prepared as \href{https://github.com/fchollet/deep-learning-with-python-notebooks}{\alert{notebooks}}.

-   **But**: When using something new, e.g. a convolution layer or optimizer, try to understand what it does and why it might be beneficial!

-   First of all, we have to load keras and import models and layers:
    ```python
    import keras # equal to Rs library command
    from keras import models
    from keras import layers
    ```

## Gettins Started with Keras - Example Data 1

\scriptsize

```python
import numpy as np
from keras.datasets import cifar10 # Our dataset
# See https://www.cs.toronto.edu/~kriz/cifar.html

(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()
X_train.shape
## (50000, 32, 32, 3)

categories = ["airplane", "automobile", "bird", "cat",
              "deer", "dog", "frog", "horse", "ship",
              "truck"]

import matplotlib.pyplot as plt

category = categories[np.asscalar(Y_train[2305])]
plt.title('Label is \"{label}\"'.format(label=category))
plt.imshow(X_train[2305], cmap='gray')
plt.show()
```
\normalsize

## Getting Started with Keras - Example Data 2

\begin{center}
  \includegraphics[width=7cm]{images/cifar10_dog.png}
\end{center}

## Getting Started with Keras - Example Data 3

The images are represented as rgb colors, each of the $32 \times 32$ pixels is represented as three numbers between 0 and 255. For the training we want to use values between 0 and 1:

\scriptsize

```python
train_images = X_train.astype('float32') / 255
test_images = X_test.astype('float32') / 255
```
\normalsize

Additionally, we have to convert the labels to a categorical data type:

\scriptsize

```python
from keras.utils import to_categorical

train_labels = to_categorical(Y_train)
test_labels = to_categorical(Y_test)
```

\normalsize

## Getting Started with Keras - DNN 1

\scriptsize

```python
network = models.Sequential()

network.add(layers.Conv2D(64, (3, 3),
            input_shape=(32, 32, 3), padding='same'))
# now: model.output_shape == (None, 64, 32, 32)

network.add(layers.Flatten())

# Add fully connected hidden layer:
network.add(layers.Dense(units=128,
                         activation='relu'))

# Add output layer which maps each category to a neuron:
network.add(layers.Dense(10, activation='softmax'))

# Make the network ready for training:
network.compile(optimizer='rmsprop',
                loss='categorical_crossentropy',
                metrics=['accuracy'])
```
\normalsize

## Getting Started with Keras - DNN 2

\scriptsize

```python
network.summary()
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #
## =================================================================
## conv2d_2 (Conv2D)            (None, 32, 32, 64)        1792
## _________________________________________________________________
## flatten_2 (Flatten)          (None, 65536)             0
## _________________________________________________________________
## dense_3 (Dense)              (None, 128)               8388736
## _________________________________________________________________
## dense_4 (Dense)              (None, 10)                1290
## =================================================================
## Total params: 8,391,818
## Trainable params: 8,391,818
## Non-trainable params: 0
## _________________________________________________________________
##
```

\normalsize

## Getting Started with Keras - DNN 3

\scriptsize

```python
# Train network:
network.fit(train_images, train_labels, epochs=20, batch_size=128)

network.evaluate(test_images, test_labels)
## [3.585078500747681, 0.4522]
```

## Getting Started with Keras - DNN 4

Now we try to predict the class of a new image. Therefore, we have to rescale the original image to the same input shape of the training images:
\begin{center}
  \includegraphics[width=\textwidth,trim={1cm 3cm 1cm 3cm}]{images/rescale_wuschel.pdf}
\end{center}

## Getting Started with Keras - DNN 5

\scriptsize

```python
from keras.preprocessing.image import load_img, img_to_array
img = load_img('wuschel.jpg', target_size=(32, 32))
img = img_to_array(img).astype('float32') / 255

plt.title('This is Wuschel')
plt.imshow(img, cmap='gray')
plt.show()
```
\begin{center}
  \includegraphics[width=5cm]{images/wuschel32x32.png}
\end{center}


## Getting Started with Keras - DNN 6

\scriptsize

```python
wuschel_pred = network.predict(np.array([img]))
wuschel_pred
## array([[0.01510279, 0.03711035, 0.04978644, 0.25755176,
##         0.03696484, 0.23572417, 0.00041433, 0.3290789 ,
##         0.00335977, 0.03490658]], dtype=float32)

categories[wuschel_pred.argmax()]
## 'horse'
```

## Getting Started with Keras - Transfer Learning 1

\scriptsize

```python
from keras.applications import VGG16

conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=(32, 32, 3))

from keras import optimizers

model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

conv_base.trainable = False

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
```

## Getting Started with Keras - Transfer Learning 2

\scriptsize

```python
model.summary()
## _________________________________________________________________
## Layer (type)                 Output Shape              Param #
## =================================================================
## vgg16 (Model)                (None, 1, 1, 512)         14714688
## _________________________________________________________________
## flatten_3 (Flatten)          (None, 512)               0
## _________________________________________________________________
## dense_5 (Dense)              (None, 256)               131328
## _________________________________________________________________
## dense_6 (Dense)              (None, 10)                2570
## =================================================================
## Total params: 14,848,586
## Trainable params: 133,898
## Non-trainable params: 14,714,688
## _________________________________________________________________
##
```

## Getting Started with Keras - Transfer Learning 3

\scriptsize

```python
# Train network:
model.fit(train_images, train_labels, epochs=20, batch_size=128)

model.evaluate(test_images, test_labels)
## [1.1461146575927734, 0.6175]
```

## Getting Started with Keras - Transfer Learning 5

\scriptsize

```python
wuschel_pred = model.predict(np.array([img]))
wuschel_pred
## array([[1.4046730e-03, 1.0323318e-03, 1.2766185e-01,
##         4.6453097e-01, 5.1652599e-02, 5.0368346e-02,
##         2.9299492e-01, 1.0088098e-02, 2.4648944e-05,
##         2.4157017e-04]], dtype=float32)

categories[wuschel_pred.argmax()]
## 'cat'
```

## What Next?

**Improving Performance:**

-   Choosing the number of epochs using early stopping
-   Data augmentation (increasing size of training data by rotating, scaling, flipping, ...)

**More Difficult Tasks:**

-   RNN, LSTM, GAN, Reinforcement Learning
-   Natural Language Processing

<!-- # Outlook

## Outlook

-   **Getting More Complex**: RNN, LSTM, GAN, Reinforcement Learning
-   **NLP**: Gensim, pre-trained word embeddings, ...
-
 -->
