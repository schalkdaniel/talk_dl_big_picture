---
title: What is Deep Learning
subtitle: The Big Picture -- From History to Todays Implementations
author: Daniel Schalk
date: \today
output:
  beamer_presentation:
    includes:
      in_header: "style/preamble_reisensburg.sty"
    template: "style/custom_pandoc.tex"
---



# History of Deep Learning

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=1]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=2]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=3]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=4]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 1

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=5]{images/dl_history1.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=1]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=2]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=3]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=4]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}

## Deep Learning Timeline - 2

\hbox{\hspace{-6.5em} \includegraphics[width=14cm,page=5]{images/dl_history2.pdf}}
\addtocounter{framenumber}{-1}



# Fascination Deep Learning

## Imitating Humans - 1

\begin{itemize}
  \item Turing test:

  \begin{minipage}{\textwidth}
    \begin{minipage}{0.6\textwidth}
    \begin{itemize}
      \item Developed by Alan Turing in 1950
      \item Test of a machine's ability to exhibit intelligent behavior
      \item Player C, the interrogator, is given the task of trying to determine which player, A or B, is a computer and which is a human
    \end{itemize}
    \end{minipage}
    \hfill
    \begin{minipage}{0.25\textwidth}
    \includegraphics[width=\textwidth]{images/turing_test.png}
    \end{minipage}
  \end{minipage}
\end{itemize}

## Imitating Humans - 2

-   Image Recognition (Seeing):
\begin{center}
\includegraphics[width=5cm,trim={1cm 0cm 1cm 0cm}]{images/image_recognition.pdf}
\end{center}

-   Speech Recognition and Text Mining (Hearing and understanding text):
\begin{center}
\includegraphics[width=7cm,trim={0cm 4cm 0cm 4cm}]{images/speech_recognition.pdf}
\end{center}

## Imitating Humans - 3

-   And know we try to learn them being creative:
    -   Music and Text Generation
    -   Neural Style Transfer:
\begin{center}
\includegraphics[width=0.7\textwidth,trim={1cm 4cm 1cm 4cm}]{images/neural_style_transfer.pdf}
\end{center}
    -   ...



# Why Deep Learning is so Powerful?

## The Perceptron

- The perceptron was invented by Frank Rosenblatt 1957.
  \begin{figure}
  \includegraphics[width=4cm]{images/mark_i_perceptron.png}
  \caption{\footnotesize The Mark I Perceptron}
  \end{figure}

- It is the basic computational unit for neural networks.

## Singlelayer Perceptron

- Weighted sum of input values transformed by an activation function $s$
- If $s$ is the sigmoid function $(1 + \exp{\sum})^{-1}$, then the perceptron does exactly the same as the logistic regression

\begin{center}
\includegraphics[width=\textwidth,trim={2cm 3cm 1cm 2cm}]{images/perceptron.pdf}
\end{center}

## Multilayer Perceptron

-   Stacking of multiple perceptrons
-   Corresponds to stacking GLM models
-   Number of parameter grows very fast \
    $\rightarrow$ Optimizing becomes more difficult

\begin{center}
\includegraphics[width=\textwidth,trim={2cm 3cm 1cm 1cm}]{images/fully_connected.pdf}
\end{center}


## Optimizer

-   Having that much parameter/weights to find, standard optimizer like Gradient Descent may fail
-   Therefore, much effort was spend to get faster optimizer like momentum, adagrad, etc.:
\begin{figure}
\includegraphics[width=0.4\textwidth]{images/optimizer.jpg}
\caption{\scriptsize \textbf{Source:} Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.}
\end{figure}

## Convolution

-   Generating of new, hopefully meaningful, features of the input (commonly images)

\begin{center}
\includegraphics[width=0.6\textwidth]{images/conv_sobel.png}
\end{center}

## Convolution

\begin{figure}
\includegraphics[width=\textwidth]{images/sobel.pdf}
\caption{\scriptsize \textbf{Note:} The recognition of edges and corners requires a multiple application of the operator.}
\end{figure}

## Pooling

-   Down-sampling of images
-   Reduces overfitting, memory usage, and therefore speeds up the fitting process

\includegraphics[width=\textwidth,trim={2cm 2cm 3cm 3cm}]{images/max_pooling.pdf}

## Lets Get Deep

-   The secret of Deep Learning is the chaining of hidden layer such as convolution layers, pooling layers, and so on
-   This deep structure allows the network to create powerful features and explore complex structures within the data
-   VGG16 architecture:

\begin{figure}
\includegraphics[width=0.5\textwidth]{images/vgg_net.png}
\caption{\scriptsize \textbf{Source:} \url{https://www.cs.toronto.edu/~frossard/post/vgg16/}}
\end{figure}



<!-- 
| Model             | Size   | Top-1 Accuracy | Top-5 Accuracy | Parameters   | Depth |
| ----------------- | ------ | -------------- | -------------- | ------------ | ----- |
| Xception          |  88 MB |          0.790 |          0.945 |  22,910,480  |  126  |
| VGG16             | 528 MB |          0.713 |          0.901 |  138,357,544 |   23  |
| VGG19             | 549 MB |          0.713 |          0.900 |  143,667,240 |   26  |
| ResNet50          |  99 MB |          0.749 |          0.921 |  25,636,712  |  168  |
| InceptionV3       |  92 MB |          0.779 |          0.937 |  23,851,784  |  159  |
| InceptionResNetV2 | 215 MB |          0.803 |          0.953 |  55,873,736  |  572  |
| MobileNet         |  16 MB |          0.704 |          0.895 |  4,253,864   |   88  |
| MobileNetV2       |  14 MB |          0.713 |          0.901 |  3,538,984   |   88  |
| DenseNet121       |  33 MB |          0.750 |          0.923 |  8,062,504   |  121  |
| DenseNet169       |  57 MB |          0.762 |          0.932 |  14,307,880  |  169  |
| DenseNet201       |  80 MB |          0.773 |          0.936 |  20,242,984  |  201  |
| NASNetMobile      |  23 MB |          0.744 |          0.919 |  5,326,716   |    -  |
| NASNetLarge       | 343 MB |          0.825 |          0.960 |  88,949,818  |    -  | 
-->

## Pre Trained Models

\scriptsize

| **Model**         | **Size** | **Parameters** | **Depth** |
| ----------------- | --------:| --------------:|:---------:|
| Xception          |  88 MB   |  22,910,480    |       126 |
| VGG16             | 528 MB   |  138,357,544   |        23 |
| VGG19             | 549 MB   |  143,667,240   |        26 |
| ResNet50          |  99 MB   |  25,636,712    |       168 |
| InceptionV3       |  92 MB   |  23,851,784    |       159 |
| InceptionResNetV2 | 215 MB   |  55,873,736    |       572 |
| MobileNet         |  16 MB   |  4,253,864     |        88 |
| MobileNetV2       |  14 MB   |  3,538,984     |        88 |
| DenseNet121       |  33 MB   |  8,062,504     |       121 |
| DenseNet169       |  57 MB   |  14,307,880    |       169 |
| DenseNet201       |  80 MB   |  20,242,984    |       201 |
| NASNetMobile      |  23 MB   |  5,326,716     |         - |
| NASNetLarge       | 343 MB   |  88,949,818    |         - |

\begin{center}
\textbf{Source:} \href{https://keras.io/applications/}{\alert{Keras Documentation}}
\end{center}

\normalsize



# Challenges in Deep Learning

## Challenges in Deep Learning

-   **Architecture Search** \
    Having that much possibilities of combining hidden layer, optimizer, and activation functions we run into the problem of finding a good architecture. \
    \begin{itemize}\item[$\rightarrow$] Transfer learning, use already trained models, adjust them to your data situation, and train (a subset of) the weights.\end{itemize}

-   **Expensive Training** \
    During the tuning of Deep Neural Networks requires billions of matrix multiplications, hence training \alert{one} DNN might take weeks. \
    \begin{itemize}\item[$\rightarrow$] Use GPU server for serious applications. Why? See next slides.\end{itemize}



# About Implementations

## Hardware

- Deep Neural Networks require special hardware to be trained efficiently.
- The training is done using **G**raphics **P**rocessing **U**nits and a special programming language called **CUDA**.
- Training on standard CPUs takes a very long long time and gets infeasible for anything but toy examples.

\begin{minipage}{0.49\textwidth}
\begin{figure}
\includegraphics[width=5cm]{images/cpu_training.pdf}
\caption{Each CPU can do $2-8$ parallel computations.}
\end{figure}
\end{minipage}
\begin{minipage}{0.49\textwidth}
\begin{figure}
\includegraphics[width=5cm]{images/gpu_training.pdf}
\caption{A single GPU can do thousands of simple parallel computations.}
\end{figure}
\end{minipage}


## Software

CUDA is a very **low level** programming language and thus writing code for Deep Learning requires a lot of work.
Software projects, like TensorFlow and abstract CUDA provide additional functionality.


\begin{minipage}{0.4\textwidth}
The basic concept of calculations in deep neural networks is a \textit{computational graph},
which describes the dependency structure of the network.
\end{minipage}
\begin{minipage}{0.58\textwidth}
\begin{figure}
\includegraphics[width=5cm]{images/compgraph1.png}
\caption{Computational graph for $f(XW + b)$.}
\end{figure}
\end{minipage}


## TensorFlow

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/tensorflow.jpeg}
\end{figure}


- Open-source framework developed by google.

- Rather low-level and aimed to directly work with computational graphs.

- Mainly support for Python (R support only via _reticulate_).

- Widely used and well documented.


## Keras

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/keras.png}
\end{figure}

- Open-source high-level API for Deep Learning.

- Can run on top of **TensorFlow**, CNTK or Theano.

- Mainly support for Python (R support only via **reticulate**).

- Widely used and well documented.

## Keras in R

\begin{minipage}{\textwidth}
  \begin{minipage}{0.5\textwidth}
    \includegraphics{images/tech_stack.png}
  \end{minipage}
  \begin{minipage}{0.5\textwidth}
    \includegraphics{images/tech_stack_R.png}
  \end{minipage}
\end{minipage}

- Deep learning in R is the same as in Python.

- Communication from R to Python via **reticulate**.

## Keras in R

- Syntax is (almost) identical.

- Same functionality.

- Same speed (slight overhead for communication between R and Python).

- More difficult to debug.

Useful resources:

\url{https://keras.rstudio.com/}

\url{https://rstudio.github.io/reticulate/articles/introduction.html}


## PyTorch

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/pytorch.png}
\end{figure}


- Open-source framework developed by facebook.

- Reimplementation of Torch.

- Only support for Python.

- Widely used and well documented.

## Fast.ai

\begin{figure}
  \centering
    \includegraphics[width=4cm]{images/fastai.png}
\end{figure}


- Open-source high-level API build on top of PyTorch.

- Still in alpha version.

- Only support for Python.

- Initially developed for the _Practical Deep Learning for Coders_ online course.

## mxnet

\begin{figure}
  \centering
    \includegraphics[width=5cm]{images/mxnet.png}
\end{figure}

- Open-source framework in the Apache foundation.

- Scalable, allow easy training on multiple GPUs in parallel.

- Supports multiple languages (C++, Python, R, Julia, Matlab, JavaScript, Go, Scala, Pearl).

- Not as widely used as other frameworks.



# Where to Start in the DL Jungle

## Getting Started with Keras - Installation

Install keras using `pip` (or pip3 for python3) from the command line:
```{r, eval=FALSE}
# python
pip install --upgrade tensorflow
pip install keras

# python3
pip3 install --upgrade tensorflow
pip3 install keras
```

On linux you may need to run the commands as `sudo`.

## Getting Started with Keras - Overview

-   Instead of introducing theory fist, we want to get into the topic by applying it.

-   We use examples from the book \href{https://www.manning.com/books/deep-learning-with-python}{\alert{Deep Learning with Python}} which are prepared as \href{https://github.com/fchollet/deep-learning-with-python-notebooks}{\alert{notebooks}}.

-   **But**: When using something new, e.g. a convolution layer or optimizer, try to understand what it does and why it might be beneficial!

## Getting Started with Keras - Example Data

\scriptsize

```python
import keras # equal to Rs library command
from keras.datasets import cifar10

(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()

import matplotlib.pyplot as plt

plt.title('Label is {label}'.format(label=Y_train[2305]))
plt.imshow(X_train[2305], cmap='gray')
plt.show()

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

plt.title('Label is {label}'.format(label=train_labels[3141]))
plt.imshow(train_images[3141], cmap='gray')
plt.show()
```
\begin{center}
  \includegraphics[width=4cm]{images/mnist_3141.png}
\end{center}

\normalsize

## Getting Started with Keras - Example Data

We need to define in keras the shape of the images. Therefore, reshaping the images to $28 \times 28$ pixels.

\scriptsize

```python
train_images = X_train.reshape((60000, 32 * 32, 3))
train_images = X_train.astype('float32') / 255
train_images = train_images.astype('float32') / 255

test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255
```

Additionally, we have to convert the labels to a categorical data type:

```python
from keras.utils import to_categorical

train_labels = to_categorical(Y_train)
test_labels = to_categorical(test_labels)
```

\normalsize

## Getting Started with Keras - First Neural Net 1

Imports the `Sequential` model which is a linear stack of layers: 

```python
from keras import models
```

Imports the layers that can be used within the `Sequential` model:

```python
from keras import layers 
```

## Getting Started with Keras - First Neural Net 2

\scriptsize

```python
network = models.Sequential()

# Add fully connected hidden layer:
network.add(layers.Dense(units=512, 
                         activation='relu', 
                         input_shape=(32 * 32, 3)))

# Add output layer which maps each category to a neuron:
network.add(layers.Dense(10, activation='softmax'))

# Make the network ready for training:
network.compile(optimizer='rmsprop',
                loss='categorical_crossentropy',
                metrics=['accuracy'])

# Train network:
network.fit(train_images, train_labels, epochs=5, batch_size=128)
```

\normalsize

## Getting Started with Keras - First Neural Net 3

-   Predict a new image:
\scriptsize
    ```python
    p = network.predict(test_images[:1])
    p
    # array([[5.9763487e-09, 3.7401582e-10, 6.6781431e-06, 
    #         3.1601216e-05, 1.4678986e-12, 6.0180113e-08, 
    #         9.2732910e-14, 9.9996114e-01, 5.4880491e-08, 
    #         4.6900539e-07]], dtype=float32)
    p.argmax()
    7
    ```
\normalsize

-   Evaluate trained network:
\scriptsize
    ```python
    network.evaluate(test_images, test_labels)
    # [0.06617570319068618, 0.9798]
    ```
\normalsize

## Getting Started with Keras - Getting Deep

Explain API

## Getting Started with Keras - Getting Deep

Some Code



## Getting Started with Keras - Transfer Learning

```python
from keras.applications import VGG16

conv_base = VGG16(weights='imagenet',
                  include_top=False,
                  input_shape=())

from keras import optimizers

model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(256, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

conv_base.trainable = False

network.compile(optimizer='rmsprop',
                loss='categorical_crossentropy',
                metrics=['accuracy'])

# Train network:
network.fit(train_images, train_labels, epochs=5, batch_size=128)
```

## Getting Started with Keras - Transfer Learning

Some Code



<!-- # Outlook

## Outlook

-   **Getting More Complex**: RNN, LSTM, GAN, Reinforcement Learning
-   **NLP**: Gensim, pre-trained word embeddings, ...
-   
 -->